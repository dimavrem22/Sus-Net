{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "root_path = pathlib.Path().absolute().parent\n",
    "sys.path.append(str(root_path))\n",
    "\n",
    "from src.train import run_experiment, OptimizerType, run_game\n",
    "from src.models.dqn import ModelType\n",
    "from src.environment.pred_prey import ImposterTrainingGround\n",
    "from src.features.model_ready import FeaturizerType\n",
    "from src.features.component import CoordinateAgentPositionsFeaturizer, CompositeFeaturizer, OneHotAgentPositionFeaturizer\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUF_SIZE = 300_000\n",
    "N_IMPOSTERS = 1\n",
    "N_JOBS = 0\n",
    "N_CREW = 1\n",
    "SEQUENCE_SIZE = 1\n",
    "env = ImposterTrainingGround(n_crew=N_CREW, n_jobs=N_JOBS, debug=False, kill_reward=-3, sabotage_reward=0, end_of_game_reward=0, time_step_reward=0)\n",
    "\n",
    "model_registry_path = root_path / 'model_registry'\n",
    "model_registry_path.mkdir(exist_ok=True)\n",
    "\n",
    "featurizer_type = FeaturizerType.FLAT\n",
    "\n",
    "experiments = [\n",
    "    '1v1_no_wall_coord_features',\n",
    "    '1v1_wall_coord_features',\n",
    "    '1v1_one_hot_no_wall',\n",
    "    '1v1_one_hot_wall',\n",
    "]\n",
    "\n",
    "envs = {\n",
    "    'Wall': ImposterTrainingGround(n_crew=N_CREW, n_jobs=N_JOBS, debug=False, kill_reward=-3, sabotage_reward=0, end_of_game_reward=0, time_step_reward=0),\n",
    "    'No Wall': ImposterTrainingGround(n_crew=N_CREW, n_jobs=N_JOBS, debug=False, kill_reward=-3, sabotage_reward=0, end_of_game_reward=0, time_step_reward=0, include_walls=False), \n",
    "}\n",
    "\n",
    "gammas = [[0.9],[0.9],[0.9],[0.9, 0.8, 0.7]]\n",
    "\n",
    "featurizers = [\n",
    "    FeaturizerType.build(FeaturizerType.FLAT, env, featurizers=CompositeFeaturizer([CoordinateAgentPositionsFeaturizer(envs['No Wall'])])),\n",
    "    FeaturizerType.build(FeaturizerType.FLAT, env, featurizers=CompositeFeaturizer([CoordinateAgentPositionsFeaturizer(envs['Wall'])])),\n",
    "    FeaturizerType.build(FeaturizerType.FLAT, env, featurizers=CompositeFeaturizer([OneHotAgentPositionFeaturizer(envs['No Wall'])])),\n",
    "    FeaturizerType.build(FeaturizerType.FLAT, env, featurizers=CompositeFeaturizer([OneHotAgentPositionFeaturizer(envs['Wall'])])),\n",
    "]\n",
    "\n",
    "configs = []\n",
    "\n",
    "base_mlp = {\n",
    "    \"layer_dims\": [256, 128, 64, 16, env.n_imposter_actions]\n",
    "}\n",
    "\n",
    "for i, experiment in enumerate(experiments):\n",
    "    for j, gamma in enumerate(gammas[i]):\n",
    "        config = {\n",
    "            'env': featurizers[i].env,\n",
    "            'num_steps': 1000,\n",
    "            'imposter_model_args': {\n",
    "                'layer_dims': [featurizers[i].featurized_shape[1].item()] + [256, 128, 64, 16, env.n_imposter_actions]\n",
    "            },\n",
    "            'crew_model_args': {'n_actions': env.n_crew_actions},\n",
    "            'imposter_model_type': ModelType.MLP,\n",
    "            'crew_model_type': ModelType.RANDOM,\n",
    "            'featurizer': featurizers[i],\n",
    "            'sequence_length': SEQUENCE_SIZE,\n",
    "            'replay_buffer_size': BUF_SIZE,\n",
    "            'replay_prepopulate_steps': 50_000,\n",
    "            'batch_size': 8,\n",
    "            'gamma': gamma,\n",
    "            'scheduler_start_eps': 1,\n",
    "            'scheduler_end_eps': 0.05,\n",
    "            'scheduler_time_steps': 1_000_000,\n",
    "            'train_imposter': True,\n",
    "            'train_crew': False,\n",
    "            'experiment_base_dir': model_registry_path / experiment,\n",
    "            'optimizer_type': OptimizerType.ADAM,\n",
    "            'learning_rate': 0.001,\n",
    "            'train_step_interval': 5,\n",
    "            'num_checkpoint_saves': 5,\n",
    "            \n",
    "        }\n",
    "        configs.append(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([str(config) for config in configs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in configs:\n",
    "    run_experiment(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imposter_model_config = {\n",
    "#     # \"layer_dims\": [imput_dim, 256,16, 16, 16, env.n_imposter_actions],\n",
    "#     'pretrained_model_path': './model_registry/1v1_imposter_no_walls/2024-04-24_11-19-34/imposter_mlp_100%.pt''\n",
    "# }\n",
    "\n",
    "# imposter_model = ModelType.build(ModelType.MLP, **imposter_model_config)\n",
    "# crew_model = ModelType.build(ModelType.RANDOM, **{'n_actions': env.n_crew_actions})\n",
    "\n",
    "# featurizer = FeaturizerType.build(FeaturizerType.FLAT, env)\n",
    "\n",
    "# run_game(env, imposter_model, crew_model, featurizer, sequence_length=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
